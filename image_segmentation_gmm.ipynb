{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from random import randint\n",
    "from functools import reduce\n",
    "def k_means_cluster(image_values, k=3, initial_means=None):\n",
    "    \"\"\"\n",
    "    Separate the provided RGB values into\n",
    "    k separate clusters using the k-means algorithm,\n",
    "    then return an updated version of the image\n",
    "    with the original values replaced with\n",
    "    the corresponding cluster values.\n",
    "    \n",
    "    params:\n",
    "    image_values = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]]\n",
    "    k = int\n",
    "    initial_means = numpy.ndarray[numpy.ndarray[float]] or None\n",
    "    \n",
    "    returns:\n",
    "    updated_image_values = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]]\n",
    "    \"\"\"\n",
    " \n",
    "    x = image_values.reshape(-1,image_values.shape[-1])\n",
    "    # Initialize inital_means if necessary\n",
    "    if initial_means is None:\n",
    "        initial_means = x[np.random.choice(x.shape[0], size=k, replace=False)]\n",
    "    u = initial_means\n",
    "    dist = np.empty(x.shape[:1] + (k,))\n",
    "    prev_r = None\n",
    "    while True:\n",
    "        # Compute sum of squares distance\n",
    "        for j in range(0,k):\n",
    "            dist[:,j] = np.sum((x[:]-u[j])**2, axis=1)\n",
    "        # Compute min sum of square distance and r\n",
    "        min_dist = np.min(dist, axis=1, out=None, keepdims=True)\n",
    "        r = dist\n",
    "        r[r == min_dist] = 1\n",
    "        r[r != 1] = 0\n",
    "        # Check for convergence\n",
    "        if (not prev_r is None) and (r == prev_r).all():\n",
    "            break\n",
    "        prev_r = np.copy(r)\n",
    "        # Compute u\n",
    "        for j in range(0,k):\n",
    "            if np.sum(r[:,j]) == 0:\n",
    "                u[j] = [0,0,0]\n",
    "            else:\n",
    "                u[j] = np.sum(r[:,j].reshape(r.shape[:1] + (1,))*x[:], axis=0)/np.sum(r[:,j], axis=0)\n",
    "    # Construct segmented image\n",
    "    r = r.astype(int)\n",
    "    updated_image_values = np.empty(image_values.shape)\n",
    "    for index in np.ndindex(updated_image_values.shape[:2]):\n",
    "        updated_image_values[index] = np.array(u[np.argmax(r[index[0]*updated_image_values.shape[1] + index[1]])])\n",
    "    return updated_image_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_test():\n",
    "    \"\"\"\n",
    "    Testing your implementation\n",
    "    of k-means on the segmented\n",
    "    bird_color_24 reference images.\n",
    "    \"\"\"\n",
    "    k_min = 2\n",
    "    k_max = 6\n",
    "    image_dir = 'images/'\n",
    "    image_name = 'bird_color_24.png'\n",
    "    image_values = image_to_matrix(image_dir + image_name)\n",
    "    # initial mean for each k value\n",
    "    initial_means = [\n",
    "        np.array([[0.90980393,0.8392157,0.65098041],[0.83137256,0.80784315,0.69411767]]),\n",
    "        np.array([[0.90980393,0.8392157,0.65098041],[0.83137256,0.80784315,0.69411767],[0.67450982,0.52941179,0.25490198]]),\n",
    "        np.array([[0.90980393,0.8392157,0.65098041],[0.83137256,0.80784315,0.69411767],[0.67450982,0.52941179,0.25490198],[0.86666667,0.8392157,0.70588237]]),\n",
    "        np.array([[0.90980393,0.8392157,0.65098041],[0.83137256,0.80784315,0.69411767],[0.67450982,0.52941179,0.25490198],[0.86666667,0.8392157,0.70588237],[0,0,0]]),\n",
    "        np.array([[0.90980393,0.8392157,0.65098041],[0.83137256,0.80784315,0.69411767],[0.67450982,0.52941179,0.25490198],[0.86666667,0.8392157,0.70588237],[0,0,0],[0.8392157,0.80392158,0.63921571]]),\n",
    "    ]\n",
    "    # test different k values to find best\n",
    "    for k in range(k_min, k_max+1):\n",
    "        updated_values = k_means_cluster(image_values, k, initial_means[k-k_min])\n",
    "        ref_image = image_dir + 'k%d_%s'%(k, image_name)\n",
    "        ref_values = image_to_matrix(ref_image)\n",
    "        dist = image_difference(updated_values, ref_values)\n",
    "        print('Image distance = %.2f'%(dist))\n",
    "        if(int(dist) == 0):\n",
    "            print('Clustering for %d clusters produced a realistic image segmentation.'%(k))\n",
    "        else:\n",
    "            print('Clustering for %d clusters didn\\'t produce a realistic image segmentation.'%(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def default_convergence(prev_likelihood, new_likelihood, conv_ctr, conv_ctr_cap=10):\n",
    "    \"\"\"\n",
    "    Default condition for increasing\n",
    "    convergence counter: \n",
    "    new likelihood deviates less than 10%\n",
    "    from previous likelihood.\n",
    "\n",
    "    params:\n",
    "    prev_likelihood = float\n",
    "    new_likelihood = float\n",
    "    conv_ctr = int\n",
    "    conv_ctr_cap = int\n",
    "\n",
    "    returns:\n",
    "    conv_ctr = int\n",
    "    converged = boolean\n",
    "    \"\"\"\n",
    "    increase_convergence_ctr = (abs(prev_likelihood) * 0.9 < \n",
    "                                abs(new_likelihood) < \n",
    "                                abs(prev_likelihood) * 1.1)\n",
    "    \n",
    "    if increase_convergence_ctr:\n",
    "        conv_ctr+=1\n",
    "    else:\n",
    "        conv_ctr =0\n",
    "        \n",
    "    return conv_ctr, conv_ctr > conv_ctr_cap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import math\n",
    "from scipy.misc import logsumexp\n",
    "class GaussianMixtureModel:\n",
    "    \"\"\"\n",
    "    A Gaussian mixture model\n",
    "    to represent a provided \n",
    "    grayscale image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_matrix, num_components, means=None):\n",
    "        \"\"\"\n",
    "        Initialize a Gaussian mixture model.\n",
    "        \n",
    "        params:\n",
    "        image_matrix = (grayscale) numpy.nparray[numpy.nparray[float]]\n",
    "        num_components = int\n",
    "        \"\"\"\n",
    "        self.image_matrix = image_matrix\n",
    "        self.num_components = num_components\n",
    "        if(means is None):\n",
    "            self.means = [0]*num_components\n",
    "        else:\n",
    "            self.means = means\n",
    "        self.variances = [0]*num_components\n",
    "        self.mixing_coefficients = [0]*num_components\n",
    "    \n",
    "    def joint_prob(self, val):\n",
    "        \"\"\"Calculate the joint \n",
    "        log probability of a greyscale\n",
    "        value within the image.\n",
    "        \n",
    "        params:\n",
    "        val = float\n",
    "        \n",
    "        returns:\n",
    "        joint_prob = float\n",
    "        \"\"\"\n",
    "        means = np.array(self.means)\n",
    "        variances = np.array(self.variances)\n",
    "        mixing = np.array(self.mixing_coefficients)\n",
    "        joint_prob = mixing*(1.0/np.sqrt(2.0*variances*math.pi))*np.exp(-1.0*((val - means)**2/(2.0*variances)))\n",
    "        \n",
    "        return math.log(np.sum(joint_prob))\n",
    "    \n",
    "    def initialize_training(self):\n",
    "        \"\"\"\n",
    "        Initialize the training\n",
    "        process by setting each\n",
    "        component mean to a random\n",
    "        pixel's value (without replacement),\n",
    "        each component variance to 1, and\n",
    "        each component mixing coefficient\n",
    "        to a uniform value \n",
    "        (e.g. 4 components -> [0.25,0.25,0.25,0.25]).\n",
    "        \n",
    "        NOTE: this should be called before \n",
    "        train_model() in order for tests\n",
    "        to execute correctly.\n",
    "        \"\"\"\n",
    "        x = self.image_matrix.flatten()\n",
    "        self.means = x[np.random.choice(x.shape[0], size=self.num_components, replace=False)].tolist()\n",
    "        self.variances[:] = [1.0] * self.num_components\n",
    "        self.mixing_coefficients[:] = [1.0/self.num_components] * self.num_components\n",
    "    \n",
    "    def train_model(self, convergence_function=default_convergence):\n",
    "        \"\"\"\n",
    "        Train the mixture model \n",
    "        using the expectation-maximization\n",
    "        algorithm. Since each Gaussian is\n",
    "        a combination of mean and variance,\n",
    "        this will fill self.means and \n",
    "        self.variances, plus \n",
    "        self.mixing_coefficients, with\n",
    "        the values that maximize\n",
    "        the overall model likelihood.\n",
    "        \n",
    "        params:\n",
    "        convergence_function = function that returns True if convergence is reached\n",
    "        \"\"\"\n",
    "        self.initialize_training()\n",
    "        log_likelihood = self.likelihood()\n",
    "        x = self.image_matrix.flatten()\n",
    "        means = np.array(self.means)\n",
    "        variances = np.array(self.variances)\n",
    "        mixing = np.array(self.mixing_coefficients)\n",
    "        count = 0\n",
    "        convergence = False\n",
    "        while not convergence:\n",
    "            # E step\n",
    "            resp = np.empty((self.num_components, x.shape[0]))\n",
    "            for k in range(0, self.num_components):\n",
    "                resp[k] = mixing[k]*(1.0/np.sqrt(2.0*variances[k]*math.pi))*np.exp(-1.0*((x - means[k])**2/(2.0*variances[k])))\n",
    "            resp = resp/np.sum(resp, axis=0)\n",
    "            resp = resp.T\n",
    "            # M step\n",
    "            means = np.sum(resp*x[:, np.newaxis], axis=0)/np.sum(resp, axis=0)\n",
    "            variances = np.sum(resp*np.square(x[:, np.newaxis] - means), axis=0)/np.sum(resp, axis=0)\n",
    "            mixing = np.sum(resp, axis=0)/resp.shape[0]\n",
    "            self.means = means\n",
    "            self.variances = variances\n",
    "            self.mixing_coefficients = mixing\n",
    "            # Evaluate likelihood and check for convergence\n",
    "            prev_likelihood = log_likelihood\n",
    "            log_likelihood = self.likelihood()\n",
    "            count, convergence = convergence_function(prev_likelihood, \n",
    "                                                      log_likelihood, \n",
    "                                                      count)\n",
    "    \n",
    "    def segment(self):\n",
    "        \"\"\"\n",
    "        Using the trained model, \n",
    "        segment the image matrix into\n",
    "        the pre-specified number of \n",
    "        components. Returns the original \n",
    "        image matrix with the each \n",
    "        pixel's intensity replaced \n",
    "        with its max-likelihood \n",
    "        component mean.\n",
    "        \n",
    "        returns:\n",
    "        segment = numpy.ndarray[numpy.ndarray[float]]\n",
    "        \"\"\"\n",
    "        x = self.image_matrix\n",
    "        means = np.array(self.means)\n",
    "        variances = np.array(self.variances)\n",
    "        mixing = np.array(self.mixing_coefficients)\n",
    "        segment = np.empty(x.shape)\n",
    "        for index in np.ndindex(segment.shape):\n",
    "            likelihoods = mixing*(1.0/np.sqrt(2.0*variances*math.pi))*np.exp(-1.0*((x[index] - means)**2/(2.0*variances)))\n",
    "            max_likelihood = np.argmax(likelihoods)\n",
    "            segment[index] = means[max_likelihood]\n",
    "        return segment\n",
    "    \n",
    "    def likelihood(self):\n",
    "        \"\"\"Assign a log \n",
    "        likelihood to the trained\n",
    "        model based on the following \n",
    "        formula for posterior probability:\n",
    "        ln(Pr(X | mixing, mean, stdev)) = sum((n=1 to N),ln(sum((k=1 to K), mixing_k * N(x_n | mean_k, stdev_k) )))\n",
    "        \n",
    "        returns:\n",
    "        log_likelihood = float [0,1]\n",
    "        \"\"\"\n",
    "        means = np.array(self.means)\n",
    "        variances = np.array(self.variances)\n",
    "        mixing = np.array(self.mixing_coefficients)\n",
    "        joint_probs = np.empty((self.num_components, x.shape[0]))\n",
    "        for k in range(0, self.num_components):\n",
    "            joint_probs[k] = mixing[k]*(1.0/np.sqrt(2.0*variances[k]*math.pi))*np.exp(-1.0*((x - means[k])**2/(2.0*variances[k])))\n",
    "        joint_probs = np.sum(joint_probs, axis=0)\n",
    "        joint_probs = np.log(joint_probs)\n",
    "        log_likelihood = np.sum(joint_probs)\n",
    "        return log_likelihood\n",
    "        \n",
    "    def best_segment(self, iters):\n",
    "        \"\"\"Determine the best segmentation\n",
    "        of the image by repeatedly \n",
    "        training the model and \n",
    "        calculating its likelihood. \n",
    "        Return the segment with the\n",
    "        highest likelihood.\n",
    "        \n",
    "        params:\n",
    "        iters = int\n",
    "        \n",
    "        returns:\n",
    "        segment = numpy.ndarray[numpy.ndarray[float]]\n",
    "        \"\"\"\n",
    "        # finish this\n",
    "        likelihoods = []\n",
    "        segments = []\n",
    "        for i in range(0, iters):\n",
    "            self.train_model()\n",
    "            likelihoods.append(self.likelihood())\n",
    "            segments.append(self.segment())\n",
    "        segment =  segments[likelihoods.index(max(likelihoods))]\n",
    "        return segment\n",
    "\n",
    "\n",
    "def gmm_likelihood_test():\n",
    "    \"\"\"Testing the GMM method\n",
    "    for calculating the overall\n",
    "    model probability.\n",
    "    \n",
    "    returns:\n",
    "    likelihood = float\n",
    "    \"\"\"\n",
    "    image_file = 'images/party_spock.png'\n",
    "    image_matrix = image_to_matrix(image_file)\n",
    "    num_components = 5\n",
    "    gmm = GaussianMixtureModel(image_matrix, num_components)\n",
    "    gmm.initialize_training()\n",
    "    gmm.means = [0.4627451, 0.10196079, 0.027450981, 0.011764706, 0.1254902]\n",
    "    likelihood = gmm.likelihood()\n",
    "    return likelihood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_joint_prob_test():\n",
    "    \"\"\"Testing the GMM method\n",
    "    for calculating the joint \n",
    "    log probability of a given point.\n",
    "    Should return -0.98196.\n",
    "    \n",
    "    returns:\n",
    "    joint_prob = float\n",
    "    \"\"\"\n",
    "    image_file = 'images/party_spock.png'\n",
    "    image_matrix = image_to_matrix(image_file)\n",
    "    num_components = 5\n",
    "    gmm = GaussianMixtureModel(image_matrix, num_components)\n",
    "    gmm.initialize_training()\n",
    "    gmm.means = [0.4627451, 0.10196079, 0.027450981, 0.011764706, 0.1254902]\n",
    "    test_val = 0.4627451\n",
    "    joint_prob = gmm.joint_prob(0.4627451)\n",
    "    return joint_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_mixture(data_size, means, variances, mixing_coefficients):\n",
    "    \"\"\"\n",
    "    Generate synthetic test\n",
    "    data for a GMM based on\n",
    "    fixed means, variances and\n",
    "    mixing coefficients.\n",
    "    \n",
    "    params:\n",
    "    data_size = (int)\n",
    "    means = [float]\n",
    "    variances = [float]\n",
    "    mixing_coefficients = [float]\n",
    "    \n",
    "    returns:\n",
    "    data = np.array[float]\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.zeros(data_size).flatten()\n",
    "\n",
    "    indices = np.random.choice( len(means), len(data), p=mixing_coefficients)\n",
    "\n",
    "    for i in range(len(indices)):\n",
    "        data[i] = np.random.normal(means[indices[i]], variances[indices[i]])\n",
    "\n",
    "    return np.array([data])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
